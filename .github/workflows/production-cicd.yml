name: Production CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily security scans at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  code-quality:
    name: Code Quality and Linting
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install black isort flake8 mypy bandit safety
    
    - name: Run Black (code formatting)
      run: |
        black --check --diff src/ tests/
    
    - name: Run isort (import sorting)
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Run flake8 (linting)
      run: |
        flake8 src/ tests/ --max-line-length=100 --ignore=E203,W503
    
    - name: Run mypy (type checking)
      run: |
        mypy src/ --ignore-missing-imports --strict-optional
    
    - name: Security scan with bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json
        bandit -r src/ --severity-level medium
    
    - name: Check dependencies for vulnerabilities
      run: |
        safety check --json --output safety-report.json
        safety check
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    strategy:
      matrix:
        python-version: ['3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-mock pytest-asyncio
    
    - name: Run unit tests with coverage
      run: |
        pytest tests/unit/ -v \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --cov-fail-under=85 \
          --junitxml=pytest-unit.xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results-${{ matrix.python-version }}
        path: |
          pytest-unit.xml
          htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: antbot_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-mock
    
    - name: Set up test environment
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/antbot_test
        REDIS_URL: redis://localhost:6379/0
      run: |
        # Create test configuration
        cp env.template .env.test
        echo "DATABASE_URL=$DATABASE_URL" >> .env.test
        echo "REDIS_URL=$REDIS_URL" >> .env.test
        echo "ENVIRONMENT=test" >> .env.test
    
    - name: Run database migrations
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/antbot_test
      run: |
        python scripts/migrate_database.py --env=test
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/antbot_test
        REDIS_URL: redis://localhost:6379/0
      run: |
        pytest tests/integration/ -v \
          --junitxml=pytest-integration.xml \
          --timeout=300
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: pytest-integration.xml

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio
    
    - name: Run security tests
      run: |
        pytest tests/security/ -v \
          --junitxml=pytest-security.xml \
          -m "security"
    
    - name: Run OWASP ZAP baseline scan
      uses: zaproxy/action-baseline@v0.7.0
      if: github.event_name == 'schedule'
      with:
        target: 'http://localhost:8000'
        rules_file_name: '.zap/rules.tsv'
        cmd_options: '-a'
    
    - name: Upload security test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-test-results
        path: |
          pytest-security.xml
          report_html.html
          report_md.md

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio psutil
    
    - name: Run performance tests
      run: |
        pytest tests/performance/ -v \
          --junitxml=pytest-performance.xml \
          -m "not slow" \
          --timeout=600
    
    - name: Run load tests (light)
      run: |
        pytest tests/performance/test_load_performance.py::TestBasicLoadTesting -v \
          --junitxml=pytest-load.xml \
          --timeout=900
    
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          pytest-performance.xml
          pytest-load.xml

  financial-safeguards-test:
    name: Financial Safeguards Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio
    
    - name: Run financial safeguard tests
      run: |
        pytest tests/unit/test_financial_safeguards.py -v \
          --junitxml=pytest-financial.xml \
          -m "financial or critical"
    
    - name: Validate production safeguards configuration
      run: |
        python -c "
        from src.core.production_safeguards import ProductionSafeguards
        config = {
            'health_check_interval': 30,
            'max_daily_loss': 0.05,
            'max_drawdown': 0.20
        }
        safeguards = ProductionSafeguards(config)
        assert len(safeguards.safeguard_rules) > 0
        print('‚úÖ Production safeguards validated')
        "
    
    - name: Upload financial test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: financial-test-results
        path: pytest-financial.xml

  end-to-end-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, security-tests]
    if: github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: antbot_e2e
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio
    
    - name: Set up E2E test environment
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/antbot_e2e
        REDIS_URL: redis://localhost:6379/0
      run: |
        # Create E2E test configuration
        cp env.template .env.e2e
        echo "DATABASE_URL=$DATABASE_URL" >> .env.e2e
        echo "REDIS_URL=$REDIS_URL" >> .env.e2e
        echo "ENVIRONMENT=e2e_test" >> .env.e2e
        echo "INITIAL_CAPITAL=0.1" >> .env.e2e  # Use minimal capital for testing
    
    - name: Run E2E tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/antbot_e2e
        REDIS_URL: redis://localhost:6379/0
      run: |
        pytest tests/e2e/ -v \
          --junitxml=pytest-e2e.xml \
          --timeout=1800
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: pytest-e2e.xml

  docker-build:
    name: Docker Build and Test
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: false
        tags: antbot:test
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Test Docker image
      run: |
        # Test image can start
        docker run --rm -d --name antbot-test \
          -e ENVIRONMENT=test \
          -e INITIAL_CAPITAL=0.01 \
          antbot:test
        
        # Wait for startup
        sleep 10
        
        # Check if container is healthy
        docker ps | grep antbot-test
        
        # Stop container
        docker stop antbot-test
    
    - name: Security scan with Trivy
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'antbot:test'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  configuration-validation:
    name: Configuration Validation
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Validate environment templates
      run: |
        python -c "
        import os
        
        # Check env.template exists and has required variables
        with open('env.template', 'r') as f:
            content = f.read()
        
        required_vars = [
            'HELIUS_API_KEY', 'JUPITER_API_KEY', 'QUICKNODE_RPC_URL',
            'WALLET_PRIVATE_KEY', 'DATABASE_URL', 'REDIS_URL'
        ]
        
        for var in required_vars:
            assert var in content, f'Missing required variable: {var}'
        
        print('‚úÖ Environment template validated')
        "
    
    - name: Validate configuration files
      run: |
        python -c "
        import json
        import yaml
        
        # Validate pytest.ini
        with open('pytest.ini', 'r') as f:
            content = f.read()
            assert 'testpaths' in content
            assert 'markers' in content
        
        # Validate docker-compose.yml
        with open('docker-compose.yml', 'r') as f:
            config = yaml.safe_load(f)
            assert 'services' in config
            assert 'antbot' in config['services']
        
        print('‚úÖ Configuration files validated')
        "
    
    - name: Validate requirements files
      run: |
        pip-compile --dry-run --check requirements.in
        python -c "
        with open('requirements.txt', 'r') as f:
            reqs = f.read()
            # Check for security-critical packages
            assert 'cryptography' in reqs
            assert 'bcrypt' in reqs or 'passlib' in reqs
        print('‚úÖ Requirements validated')
        "

  deployment-readiness:
    name: Deployment Readiness Check
    runs-on: ubuntu-latest
    needs: [
      unit-tests,
      integration-tests,
      security-tests,
      financial-safeguards-test,
      configuration-validation,
      docker-build
    ]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run deployment readiness checks
      run: |
        python scripts/deployment_readiness_check.py --strict
    
    - name: Generate deployment report
      run: |
        python scripts/generate_deployment_report.py \
          --output deployment-report.md \
          --format markdown
    
    - name: Upload deployment report
      uses: actions/upload-artifact@v3
      with:
        name: deployment-report
        path: deployment-report.md
    
    - name: Comment deployment status on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('deployment-report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## Deployment Readiness Report\n\n${report}`
          });

  staging-deployment:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [deployment-readiness, end-to-end-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to staging environment
      run: |
        echo "üöÄ Deploying to staging..."
        # Actual deployment commands would go here
        # e.g., kubectl apply, docker-compose up, etc.
    
    - name: Run smoke tests against staging
      run: |
        python scripts/smoke_tests.py --env=staging --timeout=300
    
    - name: Notify deployment status
      if: always()
      run: |
        echo "üì¢ Staging deployment completed"
        # Send notifications (Slack, email, etc.)

  production-deployment:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: staging-deployment
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Final production readiness check
      run: |
        python scripts/final_production_check.py --strict
    
    - name: Deploy to production
      run: |
        echo "üöÄ Deploying to production..."
        # Actual production deployment commands
        # Should include blue-green deployment or canary deployment
    
    - name: Run production smoke tests
      run: |
        python scripts/smoke_tests.py --env=production --timeout=300
    
    - name: Monitor deployment
      run: |
        python scripts/monitor_deployment.py --duration=300
    
    - name: Notify production deployment
      if: always()
      run: |
        echo "üéâ Production deployment completed"
        # Send critical notifications

  notification:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [
      unit-tests,
      integration-tests,
      security-tests,
      performance-tests,
      financial-safeguards-test
    ]
    if: always()
    
    steps:
    - name: Notify on failure
      if: contains(needs.*.result, 'failure')
      run: |
        echo "‚ùå Pipeline failed - critical tests did not pass"
        # Send failure notifications
    
    - name: Notify on success
      if: needs.unit-tests.result == 'success' && needs.integration-tests.result == 'success'
      run: |
        echo "‚úÖ All critical tests passed"
        # Send success notifications 